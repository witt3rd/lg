{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-U\n",
    "\n",
    "RAG-based personalization model construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models.litellm import ChatLiteLLM\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_DIR = os.getenv(\"DB_DIR\", \"./.db\")\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=DB_DIR)\n",
    "collection = chroma_client.get_or_create_collection(\"rag-u\")\n",
    "\n",
    "llm = ChatLiteLLM(model=\"groq/Llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_oracle(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "USER MODEL:\n",
    "{user_model}\n",
    "\n",
    "Given the conversation so far and the user model, update the user model with anything new you've learned about the user.\n",
    "         \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "\n",
    "def call_learner(state):\n",
    "    messages = state[\"messages\"]\n",
    "    user_model = state[\"user_model\"]\n",
    "    response = chain.invoke({\"user_model\": user_model, \"messages\": messages})\n",
    "    return {\"user_model\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    user_model: str\n",
    "\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"oracle\", call_oracle)\n",
    "graph.add_node(\"learner\", call_learner)\n",
    "graph.add_edge(\"oracle\", \"learner\")\n",
    "graph.add_edge(\"learner\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf'),\n",
       "  AIMessage(content=\"The weather in San Francisco!\\n\\nSan Francisco's climate is known for being cool and foggy, with a Mediterranean climate characterized by cool, wet winters and mild, dry summers. Here's a brief overview of what you can expect:\\n\\n**Current Weather:**\\nTo get the current weather conditions in San Francisco, I'd recommend checking a reliable weather website or app, such as:\\n\\n* National Weather Service (NWS): [www.weather.gov](http://www.weather.gov)\\n* Dark Sky (iOS, Android): A popular app that provides hyperlocal weather forecasts.\\n* Weather Underground (web, iOS, Android): A crowdsourced weather service that provides detailed forecasts.\\n\\n**Typical Weather Patterns:**\\n\\n* **Summer (June to August):** Mild temperatures, with average highs around 67°F (19°C) and lows around 54°F (12°C). Expect some fog in the mornings, which usually burns off by mid-morning.\\n* **Winter (December to February):** Cool and wet, with average highs around 51°F (11°C) and lows around 45°F (7°C). Expect more frequent and intense fog, with some rain.\\n* **Spring (March to May) and Autumn (September to November):** Mild and pleasant, with average highs\", response_metadata={'token_usage': Usage(completion_tokens=256, prompt_tokens=16, total_tokens=272), 'model': 'groq/Llama3-70b-8192', 'finish_reason': 'length'}, id='run-e99edb79-7bbd-42a5-94d2-b4460e0778f9-0')],\n",
       " 'user_model': [AIMessage(content=\"It seems like you didn't finish your question or statement. If you meant to ask about the current weather in San Francisco, I can suggest checking a reliable weather website or app, such as the National Weather Service or Dark Sky, for the most up-to-date information.\\n\\nIf you have any other questions or need help with something else, feel free to ask!\", response_metadata={'token_usage': Usage(completion_tokens=72, prompt_tokens=321, total_tokens=393), 'model': 'groq/Llama3-70b-8192', 'finish_reason': 'stop'}, id='run-289c9caa-f994-441b-b3d2-56f0013691ca-0')]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\"I need you to help solve a problem\")]}\n",
    "runnable.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = \"\"\"\n",
    "\"Starfish: Demonstrating the Future of AI-Powered Professional Networking and Task Management\"\n",
    "In the forthcoming tech demo for the Starfish project, we aim to showcase the innovative use of Digital Doubles within our Work Marketplace, illustrating the seamless integration of AI-powered agents in enhancing professional workflows and facilitating project completions. The demonstration will focus on how Digital Doubles can effectively represent individuals, manage multi-agent collaborations, and utilize feedback mechanisms for continuous learning and personalization. Specifically, the demo will feature several scenarios where Digital Doubles orchestrate diverse AI tools and systems to accomplish designated tasks that are part of a larger project structure, based on the detailed skills profiles of their human counterparts.\n",
    "This demonstration will simulate a realistic work environment where multiple professionals, equipped with their Digital Doubles, collaborate on a complex project. Here’s the envisioned flow:\n",
    "Simulation of Skill Matching and Task Allocation: Display how Digital Doubles analyze available projects and tasks within the marketplace, aligning their human counterparts' skills and career aspirations with the needs of potential employers or project leaders.\n",
    "Collaborative Project Execution: Show multiple Digital Doubles interacting with each other and with various specialized AI systems to perform tasks. This will demonstrate their capability to manage resources, time, and communication effectively, increasing project efficiency.\n",
    "Dynamic Learning and Adaptation: Highlight how these Digital Doubles receive and integrate feedback in real-time to improve their performance and adapt their strategies to meet project goals better.\n",
    "Outcome Showcase and Feedback Loop: At the end of the demo, the results of the project tasks managed by the Digital Doubles will be evaluated to demonstrate the efficacy of the digital representation and the multilayered AI interaction.\n",
    "User Interaction and Control Over Digital Double: Briefly demonstrate how individuals can set preferences, supervise task execution, and refine the learning parameters of their Digital Doubles, ensuring they remain aligned with personal growth and professional objectives.\n",
    "Technological Integration and Data Security: Explain the underlying technology that enables seamless orchestration of AI agents, the personalization processes for individual learning, and robust data security measures that protect users' information and uphold trust in the digital platform.\n",
    "This tech demo aims not only to illustrate the capabilities of Digital Doubles but also to foster discussions on the potential directions and expansions possible within the LinkedIn ecosystem, empowering users to harness the full potential of AI in the evolving digital economy. This will help us refine our approach, gather valuable feedback, and drive continued innovation in the application of AI in professional networking and task management.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dothomps/.pyenv/versions/3.11.9/envs/lg/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/dothomps/.pyenv/versions/3.11.9/envs/lg/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_info\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import itemgetter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models.litellm import ChatLiteLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_DIR = os.getenv(\"DB_DIR\", \"./.db\")\n",
    "\n",
    "#\n",
    "\n",
    "llm = ChatLiteLLM(model=\"groq/Llama3-70b-8192\")\n",
    "output_parser = StrOutputParser()\n",
    "analysis_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "- Text history analysis reveals personality, behavior, preferences.\n",
    "- Language use indicates literacy, education, regionality, style complexity, sentence structure.\n",
    "- Communication skills apparent through message clarity, response length, topic adherence.\n",
    "- Personality traits inferred from communication style, emoji use, expressiveness.\n",
    "- Interests, hobbies discernible via discussion topics.\n",
    "- Emotional state gauged from mood expressions, texting patterns.\n",
    "- Social network, relationships inferred from contact interactions.\n",
    "- Cultural background shown through references to customs, festivals.\n",
    "- Professional, academic interests indicated by specific topic discussions.\n",
    "- Values, beliefs reflected in topic responses, discussions.\n",
    "- Behavioral patterns observed in communication timing, responsiveness.\n",
    "\"\"\".strip(),\n",
    "        ),\n",
    "        (\n",
    "            \"ai\",\n",
    "            \"\"\"\n",
    "Consider the conversation so far:\n",
    "{messages}\n",
    "\n",
    "And the user's profile:\n",
    "{user_profile}\n",
    "\n",
    "Can you infer anything new about the user that isn't already in the profile?\n",
    "Indicate your edits to the user profile (add/update/delete).\n",
    "No narrative, just pure user profile revisions.\n",
    "\"\"\".strip(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "analysis_chain = analysis_prompt | llm | output_parser\n",
    "\n",
    "consolidate_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "You are a bullet list editor.  You only respond with edited bullet lists.\n",
    "\"\"\".strip(),\n",
    "        ),\n",
    "        (\n",
    "            \"ai\",\n",
    "            \"\"\"\n",
    "Consider the original user profile:\n",
    "{user_profile}\n",
    "\n",
    "Here are suggested revisions:\n",
    "{user_profile_revisions}\n",
    "\n",
    "Generate a new, consolidated user profile based on these revisions.\n",
    "No narrative, just a bullet list of user profile traits.\n",
    "\"\"\".strip(),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "user_profile_runnable = (\n",
    "    {\n",
    "        \"user_profile_revisions\": analysis_chain,\n",
    "        \"user_profile\": itemgetter(\"user_profile\"),\n",
    "    }\n",
    "    | consolidate_prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the revised bullet list:\n",
      "\n",
      "• **Interests:** AI, Advanced Agents, Automation, Professional Settings\n",
      "• **Professional Background:** AI, Technology, or Entrepreneurship\n",
      "• **Current Project:** Developing digital doubles of professionals\n",
      "• **Communication Style:** Clear, concise, goal-oriented\n",
      "• **Values:** Innovative, entrepreneurial, efficient\n"
     ]
    }
   ],
   "source": [
    "user_profile = \"\"\"\n",
    "(not provided)\n",
    "\"\"\".strip()\n",
    "res = user_profile_runnable.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Hi!\"),\n",
    "            (\"ai\", \"Hello! How can I help you today?\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"I need help making a demo for a big tchnical presentation in 1 week!\",\n",
    "            ),\n",
    "            (\"ai\", \"I can help with that! What are you presenting on?\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"We are starting a new venture in AI using advanced agents as 'digital doubles' of professionals.\",\n",
    "            ),\n",
    "            (\n",
    "                \"ai\",\n",
    "                \"That sounds interesting! What kind of help do you need with the demo?\",\n",
    "            ),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"I need to show how our agents can be used to automate tasks in a professional setting.\",\n",
    "            ),\n",
    "            (\n",
    "                \"ai\",\n",
    "                \"Got it! I can help you with that. What kind of tasks do you want to automate?\",\n",
    "            ),\n",
    "        ],\n",
    "        \"user_profile\": user_profile,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
